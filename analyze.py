import pandas as pd
import psycopg2
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

DB_CONFIG = { 'user': 'postgres', 'password': 'Quan@', 'host': 'localhost', 'port': '5432', 'database': 'flood_alert_db' }

# (Logic t·∫°o nh√£n C·∫£nh b√°o - Gi·ªØ nguy√™n)
def create_target_labels(df):
    countdown = df['time_until_a_danger'].fillna(0); mucnuoca = df['mucnuoca'].fillna(0)
    conditions = [(countdown > 0)&(countdown <= 30), (countdown > 0)&(countdown <= 60), (countdown > 60), (countdown == 0)&(mucnuoca > 28), (countdown == 0)&(mucnuoca > 25), (countdown == 0)&(mucnuoca > 20)]
    choices = ['Nguy hi·ªÉm!', 'C·∫£nh b√°o Cao!', 'C·∫£nh b√°o!', 'Nguy hi·ªÉm!', 'C·∫£nh b√°o Cao!', 'C·∫£nh b√°o!']
    return np.select(conditions, choices, default='B√¨nh th∆∞·ªùng')

# ===== S·ª¨A 1: H√ÄM T·∫†O 7 ƒê·∫∂C TR∆ØNG =====
def create_features_from_db(df):
    print("ƒêang t·∫°o 7 ƒë·∫∑c tr∆∞ng th√¥ng minh (Rain ON/OFF)...")
    df = df.sort_values(by='created_at')

    df['time_diff'] = df['created_at'].diff().dt.total_seconds().fillna(0)
    df['b_rate_of_change'] = df['mucnuocb'].diff() / df['time_diff']
    df['flow_rate_of_change'] = df['luuluong'].diff() / df['time_diff']
    df['ab_diff'] = df['mucnuocb'] - df['mucnuoca']

    # T·∫°o is_raining_now: N·∫øu countdown > 0 th√¨ ƒëang c√≥ l≈© (=> ƒëang m∆∞a)
    # (ƒê√¢y l√† c√°ch suy lu·∫≠n ng∆∞·ª£c v√¨ ch√∫ng ta kh√¥ng l∆∞u isRaining v√†o DB)
    df['is_raining_now'] = df['time_until_a_danger'].apply(lambda x: 1 if pd.notnull(x) and x > 0 else 0)

    df = df.replace([np.inf, -np.inf], 0)
    df = df.fillna(0)
    return df
# =====================================

print("ƒêang k·∫øt n·ªëi t·ªõi PostgreSQL...")
try:
    conn = psycopg2.connect(**DB_CONFIG)
    query = "SELECT * FROM public.sensor_data;" # L·∫•y h·∫øt CSDL
    df = pd.read_sql_query(query, conn)
    conn.close()
    print(f"‚úÖ L·∫•y d·ªØ li·ªáu th√†nh c√¥ng! T·ªïng c·ªông {len(df)} h√†ng.")

    df_features = create_features_from_db(df)

    # ===== S·ª¨A 2: ƒê·∫¶U V√ÄO L√Ä 7 ƒê·∫∂C TR∆ØNG =====
    features = [
        'mucnuoca',
        'mucnuocb',
        'luuluong',
        'is_raining_now',        # <-- TH√äM M·ªöI
        'b_rate_of_change',
        'flow_rate_of_change',
        'ab_diff'
    ]
    X = df_features[features]
    y = create_target_labels(df_features) # Target v·∫´n gi·ªØ nguy√™n
    unique_labels = np.unique(y)

    if len(unique_labels) < 2: print(f"‚ùå L·ªói: Ch·ªâ c√≥ 1 l·ªõp '{unique_labels[0]}'.")
    else:
        print(f"‚úÖ D·ªØ li·ªáu c√≥ {len(unique_labels)} l·ªõp: {unique_labels}")
        print("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh C·∫¢NH B√ÅO (7-features)...")
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
        model.fit(X_train, y_train)
        print("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
        predictions = model.predict(X_test)
        accuracy = accuracy_score(y_test, predictions)
        print(f"üìä ƒê·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh C·∫£nh b√°o: {accuracy * 100:.2f}%")
        joblib.dump(model, 'flood_model.pkl')
        print("‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh C·∫£nh b√°o v√†o file 'flood_model.pkl'.")
except Exception as e: print(f"‚ùå L·ªói: {e}")