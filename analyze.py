import pandas as pd
import psycopg2
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import numpy as np
from datetime import datetime, date

DB_CONFIG = { 
    'user': 'postgres', 
    'password': 'Quan@', 
    'host': 'localhost', 
    'port': '5432', 
    'database': 'flood_alert_db' 
}

def create_target_labels(df):
    """
    Táº¡o nhÃ£n cáº£nh bÃ¡o THÃ”NG MINH HÆ N - Nháº¡y cáº£m vá»›i nÆ°á»›c dÃ¢ng máº¡nh
    """
    # ğŸ†š CHUYá»‚N Äá»”I SANG Sá»
    countdown = pd.to_numeric(df['time_until_a_danger'], errors='coerce').fillna(0)
    mucnuoca = pd.to_numeric(df['mucnuoca'], errors='coerce').fillna(0)
    mucnuocb = pd.to_numeric(df['mucnuocb'], errors='coerce').fillna(0)
    
    # ğŸ¯ TÃNH TOÃN THAY Äá»”I THEO THá»œI GIAN
    df_sorted = df.sort_values(by='created_at')
    df_sorted['mucnuocb_prev'] = df_sorted['mucnuocb'].shift(1)
    df_sorted['mucnuocb_change'] = df_sorted['mucnuocb'] - df_sorted['mucnuocb_prev']
    df_sorted['mucnuocb_change'] = df_sorted['mucnuocb_change'].fillna(0)
    
    # ğŸš¨ ÄIá»€U KIá»†N Cáº¢NH BÃO Má»šI - NHáº Y Cáº¢M HÆ N
    conditions = [
        # ğŸš¨ NGUY HIá»‚M: Countdown ngáº¯n HOáº¶C má»±c nÆ°á»›c cao HOáº¶C thay Ä‘á»•i lá»›n
        (countdown > 0) & (countdown <= 30),
        (countdown == 0) & (mucnuoca > 25),
        (mucnuocb > 15),  # Má»±c nÆ°á»›c B cao
        (df_sorted['mucnuocb_change'] > 8),  # TÄƒng Ä‘á»™t biáº¿n 8cm
        (mucnuocb - mucnuoca > 10),  # ChÃªnh lá»‡ch lá»›n giá»¯a B vÃ  A
        
        # ğŸ”¶ Cáº¢NH BÃO CAO: Countdown trung bÃ¬nh HOáº¶C má»±c nÆ°á»›c trung bÃ¬nh HOáº¶C thay Ä‘á»•i trung bÃ¬nh
        (countdown > 30) & (countdown <= 90),
        (countdown == 0) & (mucnuoca > 20) & (mucnuoca <= 25),
        (mucnuocb > 12) & (mucnuocb <= 15),
        (df_sorted['mucnuocb_change'] > 4) & (df_sorted['mucnuocb_change'] <= 8),
        (mucnuocb - mucnuoca > 6) & (mucnuocb - mucnuoca <= 10),
        
        # âš ï¸ Cáº¢NH BÃO: Countdown dÃ i HOáº¶C má»±c nÆ°á»›c tháº¥p HOáº¶C thay Ä‘á»•i nhá»
        (countdown > 90) & (countdown <= 180),
        (countdown == 0) & (mucnuoca > 15) & (mucnuoca <= 20),
        (mucnuocb > 8) & (mucnuocb <= 12),
        (df_sorted['mucnuocb_change'] > 2) & (df_sorted['mucnuocb_change'] <= 4),
        (mucnuocb - mucnuoca > 3) & (mucnuocb - mucnuoca <= 6)
    ]
    
    choices = [
        'Nguy hiá»ƒm!', 'Nguy hiá»ƒm!', 'Nguy hiá»ƒm!', 'Nguy hiá»ƒm!', 'Nguy hiá»ƒm!',
        'Cáº£nh bÃ¡o Cao!', 'Cáº£nh bÃ¡o Cao!', 'Cáº£nh bÃ¡o Cao!', 'Cáº£nh bÃ¡o Cao!', 'Cáº£nh bÃ¡o Cao!',
        'Cáº£nh bÃ¡o!', 'Cáº£nh bÃ¡o!', 'Cáº£nh bÃ¡o!', 'Cáº£nh bÃ¡o!', 'Cáº£nh bÃ¡o!'
    ]
    
    return np.select(conditions, choices, default='BÃ¬nh thÆ°á»ng')

def create_features_from_db(df):
    """
    Táº¡o Ä‘áº·c trÆ°ng NÃ‚NG CAO vá»›i nhiá»u chá»‰ sá»‘ nguy hiá»ƒm
    """
    print("ğŸ”„ Äang táº¡o Ä‘áº·c trÆ°ng NÃ‚NG CAO tá»« dá»¯ liá»‡u NGÃ€Y HÃ”M NAY...")
    df = df.sort_values(by='created_at')

    # ğŸ†š CHUYá»‚N Äá»”I Sá»
    df['mucnuoca'] = pd.to_numeric(df['mucnuoca'], errors='coerce').fillna(0)
    df['mucnuocb'] = pd.to_numeric(df['mucnuocb'], errors='coerce').fillna(0)
    df['luuluong'] = pd.to_numeric(df['luuluong'], errors='coerce').fillna(0)
    df['time_until_a_danger'] = pd.to_numeric(df['time_until_a_danger'], errors='coerce').fillna(0)

    # ğŸ“Š TÃNH TOÃN Äáº¶C TRÆ¯NG NÃ‚NG CAO
    df['time_diff'] = df['created_at'].diff().dt.total_seconds().fillna(0)
    
    # Tá»‘c Ä‘á»™ thay Ä‘á»•i
    df['b_rate_of_change'] = df['mucnuocb'].diff() / df['time_diff']
    df['flow_rate_of_change'] = df['luuluong'].diff() / df['time_diff']
    
    # ChÃªnh lá»‡ch
    df['ab_diff'] = df['mucnuocb'] - df['mucnuoca']
    df['ab_ratio'] = df['mucnuocb'] / (df['mucnuoca'] + 0.001)  # TrÃ¡nh chia 0
    
    # Thay Ä‘á»•i tuyá»‡t Ä‘á»‘i
    df['b_absolute_change'] = df['mucnuocb'].diff().fillna(0)
    df['b_total_rise'] = df['mucnuocb'] - df['mucnuocb'].iloc[0]  # Tá»•ng má»©c tÄƒng tá»« Ä‘áº§u
    
    # Chá»‰ sá»‘ nguy hiá»ƒm tá»•ng há»£p
    df['danger_index'] = (
        (df['mucnuocb'] * 0.3) + 
        (df['b_rate_of_change'].abs() * 2.0) + 
        (df['b_absolute_change'].abs() * 0.5) +
        (df['ab_diff'] * 0.2)
    )
    
    # ğŸ¯ DÃ™NG Dá»® LIá»†U is_raining THá»°C Táº¾
    df['is_raining_now'] = df['is_raining'].astype(int)
    
    # Xá»­ lÃ½ giÃ¡ trá»‹ vÃ´ cÃ¹ng vÃ  NaN
    df = df.replace([np.inf, -np.inf], 0).fillna(0)
    
    print(f"   ğŸ“Š Má»±c nÆ°á»›c B: {df['mucnuocb'].min():.1f} - {df['mucnuocb'].max():.1f} cm")
    print(f"   ğŸ“Š Chá»‰ sá»‘ nguy hiá»ƒm: {df['danger_index'].min():.1f} - {df['danger_index'].max():.1f}")
    
    return df

print("ğŸŒ Äang káº¿t ná»‘i tá»›i PostgreSQL...")
try:
    conn = psycopg2.connect(**DB_CONFIG)
    
    # ğŸ¯ CHá»ˆ Láº¤Y Dá»® LIá»†U NGÃ€Y HÃ”M NAY
    today = date.today().strftime('%Y-%m-%d')
    query = f"SELECT * FROM public.sensor_data WHERE DATE(created_at) = '{today}';"
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    print(f"âœ… Láº¥y dá»¯ liá»‡u NGÃ€Y {today} thÃ nh cÃ´ng! Tá»•ng cá»™ng {len(df)} hÃ ng.")

    if len(df) < 5:
        print(f"âŒ QuÃ¡ Ã­t dá»¯ liá»‡u ({len(df)} hÃ ng). Cáº§n Ã­t nháº¥t 5 hÃ ng Ä‘á»ƒ huáº¥n luyá»‡n.")
        exit()

    # Táº¡o features vÃ  labels
    df_features = create_features_from_db(df)
    features = [
        'mucnuoca', 'mucnuocb', 'luuluong', 'is_raining_now',
        'b_rate_of_change', 'flow_rate_of_change', 'ab_diff', 
        'ab_ratio', 'b_absolute_change', 'b_total_rise', 'danger_index'
    ]
    
    X = df_features[features]
    y = create_target_labels(df_features)
    
    # PhÃ¢n tÃ­ch dá»¯ liá»‡u
    unique_labels, label_counts = np.unique(y, return_counts=True)
    print(f"ğŸ“Š PhÃ¢n phá»‘i labels NGÃ€Y HÃ”M NAY:")
    for label, count in zip(unique_labels, label_counts):
        print(f"   {label}: {count} samples")

    if len(unique_labels) < 2:
        print("âš ï¸ Cáº£nh bÃ¡o: Dá»¯ liá»‡u chá»‰ cÃ³ 1 lá»›p, model cÃ³ thá»ƒ khÃ´ng hiá»‡u quáº£")
    
    # Huáº¥n luyá»‡n model vá»›i Ä‘iá»u chá»‰nh cho dá»¯ liá»‡u nhá»
    test_size = min(0.3, 0.1 if len(df) < 20 else 0.2)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y if len(unique_labels) > 1 else None
    )
    
    # Äiá»u chá»‰nh hyperparameters cho dá»¯ liá»‡u nhá»
    n_estimators = min(50, len(X_train) // 2)
    max_depth = min(10, max(3, len(X_train) // 5))
    
    model = RandomForestClassifier(
        n_estimators=max(10, n_estimators),
        max_depth=max_depth,
        random_state=42,
        min_samples_split=2,
        min_samples_leaf=1
    )
    
    print(f"ğŸ¯ Training model vá»›i {n_estimators} trees, max_depth={max_depth}...")
    model.fit(X_train, y_train)
    
    # ÄÃ¡nh giÃ¡ model
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    
    print("\nğŸ“ˆ Káº¾T QUáº¢ MODEL PHÃ‚N LOáº I NÃ‚NG CAO:")
    print(f"   âœ… Äá»™ chÃ­nh xÃ¡c: {accuracy * 100:.2f}%")
    print(f"   ğŸ“Š Sá»‘ máº«u training: {len(X_train)}")
    print(f"   ğŸ“Š Sá»‘ máº«u testing: {len(X_test)}")
    
    # PhÃ¢n tÃ­ch feature importance
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nğŸ” Feature Importance:")
    for _, row in feature_importance.head(5).iterrows():
        print(f"   {row['feature']}: {row['importance']:.3f}")
    
    # LÆ°u model
    model_filename = f'flood_model_today.pkl'
    joblib.dump(model, model_filename)
    print(f"ğŸ’¾ ÄÃ£ lÆ°u model phÃ¢n loáº¡i NÃ‚NG CAO vÃ o '{model_filename}'")
    
    # Hiá»ƒn thá»‹ chi tiáº¿t phÃ¢n loáº¡i
    if len(unique_labels) > 1:
        print("\nğŸ” BÃ¡o cÃ¡o chi tiáº¿t:")
        print(classification_report(y_test, predictions))
    
    # Dá»± Ä‘oÃ¡n thá»­ trÃªn dá»¯ liá»‡u gáº§n Ä‘Ã¢y
    print("\nğŸ¯ Dá»° ÄOÃN THá»¬ TRÃŠN 5 MáºªU Gáº¦N ÄÃ‚Y:")
    recent_data = X.tail(5)
    recent_predictions = model.predict(recent_data)
    recent_proba = model.predict_proba(recent_data)
    
    for i, (pred, proba) in enumerate(zip(recent_predictions, recent_proba)):
        prob_dict = dict(zip(model.classes_, proba))
        print(f"   Máº«u {i+1}: {pred} (XÃ¡c suáº¥t: {prob_dict})")
        
except Exception as e:
    print(f"âŒ Lá»—i: {e}")
    import traceback
    traceback.print_exc()